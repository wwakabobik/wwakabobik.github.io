<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>wwakabobik's lair - ai</title><link href="https://wwakabobik.github.io/" rel="alternate"></link><link href="https://wwakabobik.github.io/feeds/ai.atom.xml" rel="self"></link><id>https://wwakabobik.github.io/</id><updated>2023-10-23T12:57:34+02:00</updated><entry><title>Making AI chatbot to hear and speak</title><link href="https://wwakabobik.github.io/2023/09/ai_learning_to_hear_and_speak/" rel="alternate"></link><published>2023-09-07T11:08:00+02:00</published><updated>2023-10-23T12:57:34+02:00</updated><author><name>wwakabobik</name></author><id>tag:wwakabobik.github.io,2023-09-07:/2023/09/ai_learning_to_hear_and_speak/</id><summary type="html">&lt;p class="first last"&gt;Learning to interact with chatbots in a natural way. How to make a bot speak and listen using Python&lt;/p&gt;
</summary><content type="html">&lt;p&gt;I really like the concept when you can expand the possibilities of perception for artificial intelligence. Today, the chat format is the most understandable and popular for interacting with AI. Of course, communication only through chat warms my introverted soul, brought up on &lt;a class="reference external" href="https://en.wikipedia.org/wiki/FidoNet"&gt;BBS&lt;/a&gt; and stories about &lt;a class="reference external" href="http://www.bofharchive.com/"&gt;BOFH&lt;/a&gt;. But, nevertheless, why not make communication with bots more human, teach them to listen, hear and speak? Everything that will be discussed further in the article is not some kind of unique killer-feature, and has been used in many services that provide access to artificial intelligence, for example, in &lt;a class="reference external" href="https://ablt.ai/"&gt;aBLT.ai&lt;/a&gt; chats. In this article, I want to talk about a Python solution available to anyone.&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/Ph7EQSZPmGc?si=2AgO98dUN2ihiVW-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen&gt;&lt;/iframe&gt;&lt;div class="section" id="transcriptions"&gt;
&lt;h2&gt;Transcriptions&lt;/h2&gt;
&lt;div class="section" id="openai-audio-transcribe"&gt;
&lt;h3&gt;openai.Audio.transcribe&lt;/h3&gt;
&lt;p&gt;You are most likely using ChatGPT as your main LLM engine. If you turn to its &lt;a class="reference external" href="https://platform.openai.com/docs/introduction"&gt;API&lt;/a&gt;, you can find a special &lt;strong&gt;whisper-1&lt;/strong&gt; model, which is also responsible for text transcription. All you need to do to transcribe your voice into text is call the &lt;strong&gt;openai.Audio.atranscribe method&lt;/strong&gt;. Here and below, I will use asynchronous methods where possible. This is more convenient for implementing parallel execution and running.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;openai&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prompt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;response_format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Wrapper for the transcribe function. Returns only the content of the message.&lt;/span&gt;

&lt;span class="sd"&gt;    :param file: Path with filename to transcript.&lt;/span&gt;
&lt;span class="sd"&gt;    :param prompt: Previous prompt. Default is None.&lt;/span&gt;
&lt;span class="sd"&gt;    :param language: Language on which audio is. Default is &amp;#39;en&amp;#39;.&lt;/span&gt;
&lt;span class="sd"&gt;    :param response_format: default response format, by default is &amp;#39;text&amp;#39;.&lt;/span&gt;
&lt;span class="sd"&gt;                           Possible values are: json, text, srt, verbose_json, or vtt.&lt;/span&gt;


&lt;span class="sd"&gt;    :return: transcription (text, json, srt, verbose_json or vtt)&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;kwargs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;prompt&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;prompt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;prompt&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;openai&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Audio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;atranscribe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;whisper-1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;response_format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;response_format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;temperature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To call this function, we just pass a file to it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;transcript&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# this method is for prompting LLM using pure string&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Using a pre-made file is fine, but for the sake of completeness: is it worth assuming that you probably want to record your voice on the fly?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="recording-audio-sounddevice"&gt;
&lt;h3&gt;Recording audio: sounddevice&lt;/h3&gt;
&lt;p&gt;The easiest way is to use &lt;strong&gt;sounddevice&lt;/strong&gt;. Since &lt;strong&gt;sounddevice&lt;/strong&gt; records a file in &lt;strong&gt;wav&lt;/strong&gt; format, it is reasonable to convert it to &lt;strong&gt;mp3&lt;/strong&gt; for transmission over the Internet, for this you can use, for example, &lt;strong&gt;pydab&lt;/strong&gt;. As a result, the code will look something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;uuid&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sounddevice&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;soundfile&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sf&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pydub&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;record_and_convert_audio&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;duration&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frequency_sample&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Records audio for a specified duration and converts it to MP3 format.&lt;/span&gt;

&lt;span class="sd"&gt;This function records audio for a given duration (in seconds) with a specified frequency sample.&lt;/span&gt;
&lt;span class="sd"&gt;The audio is then saved as a temporary .wav file, converted to .mp3 format, and the .wav file is deleted.&lt;/span&gt;
&lt;span class="sd"&gt;The function returns the path to the .mp3 file.&lt;/span&gt;

&lt;span class="sd"&gt;:param duration: The duration of the audio recording in seconds. Default is 5 seconds.&lt;/span&gt;
&lt;span class="sd"&gt;:param frequency_sample: The frequency sample rate of the audio recording. Default is 16000 Hz.&lt;/span&gt;

&lt;span class="sd"&gt;:return: The path to the saved .mp3 file.&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Listening beginning for &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;duration&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;s...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;recording&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;duration&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;frequency_sample&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;samplerate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;frequency_sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# Wait until recording is finished&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Recording complete!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;temp_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gettempdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;wave_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.wav&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;sf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;wave_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recording&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frequency_sample&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Temp audiofile saved: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;wave_file&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_wav&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;wave_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;wave_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;mp3_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.mp3&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;export&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mp3_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Audio converted to MP3 and stored into &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;mp3_file&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mp3_file&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The resulting file can already be fed to the model. But the method looks very clumsy, because the recording continues for a fixed time, no matter how long you speak - less than the set interval and you have to wait for the end of the recording; or more, which will lead to the phrase being cut off. Usually the smartest solution is to implement push-to-talk. While the user presses the button, the recording is in progress. This is how instant messengers and many online chats work.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="recording-audio-audiorecorder"&gt;
&lt;h3&gt;Recording audio: AudioRecorder&lt;/h3&gt;
&lt;p&gt;But I still don't think it's smart enough, because it doesn't fit with the concept of AI having ears. As a console user, it would be more convenient for me to make an implementation without any buttons and keyboard interactions, and always it's better to assign this task to the code. That is: listen constantly, and if speech is noticed in the noise, then recognize it. Well, almost like how Google Assistant, Siri, and smart speakers work in your home. If you don't need to respond to any sound, you can always filter your catch phrase to be recognized first (at the start of the recording).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;

&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;hellos*,?s*bunny&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;IGNORECASE&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;prompt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;IGNORECASE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lstrip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prompt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Well, for this task you can use for example my &lt;strong&gt;AudioRecorder&lt;/strong&gt; based on &lt;strong&gt;pyaudio&lt;/strong&gt;. It will listen to the microphone and detect noise (speech) against the background of silence using the &lt;strong&gt;RMS&lt;/strong&gt; (Root Mean Square) method. Full implementation below.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;struct&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;uuid&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;wave&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pyaudio&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pydub&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;AudioRecorder&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    The AudioRecorder class is for managing an instance of the audio recording and conversion process.&lt;/span&gt;

&lt;span class="sd"&gt;    Parameters:&lt;/span&gt;
&lt;span class="sd"&gt;    pyaudio_obj (PyAudio): Instance of PyAudio. Default is pyaudio.PyAudio().&lt;/span&gt;
&lt;span class="sd"&gt;    threshold (int): The RMS threshold for starting the recording. Default is 15.&lt;/span&gt;
&lt;span class="sd"&gt;    channels (int): The number of channels in the audio stream. Default is 1.&lt;/span&gt;
&lt;span class="sd"&gt;    chunk (int): The number of frames per buffer. Default is 1024.&lt;/span&gt;
&lt;span class="sd"&gt;    f_format (int): The format of the audio stream. Default is pyaudio.paInt16.&lt;/span&gt;
&lt;span class="sd"&gt;    rate (int): The sample rate of the audio stream. Default is 16000 Hz.&lt;/span&gt;
&lt;span class="sd"&gt;    sample_width (int): The sample width (in bytes) of the audio stream. Default is 2.&lt;/span&gt;
&lt;span class="sd"&gt;    timeout_length (int): The length of the timeout for the recording (in seconds). Default is 2 seconds.&lt;/span&gt;
&lt;span class="sd"&gt;    temp_dir (str): The directory for storing the temporary .wav and .mp3 files. Default is the system&amp;#39;s temporary dir.&lt;/span&gt;
&lt;span class="sd"&gt;    normalize (float): The normalization factor for the audio samples. Default is 1.0 / 32768.0.&lt;/span&gt;
&lt;span class="sd"&gt;    pa_input (bool): Specifies whether the stream is an input stream. Default is True.&lt;/span&gt;
&lt;span class="sd"&gt;    pa_output (bool): Specifies whether the stream is an output stream. Default is True.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;pyaudio_obj&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pyaudio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PyAudio&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
        &lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;chunk&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;f_format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pyaudio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;paInt16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;16000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;sample_width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;timeout_length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gettempdir&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
        &lt;span class="n"&gt;normalize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;32768.0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;pa_input&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;pa_output&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        General init.&lt;/span&gt;

&lt;span class="sd"&gt;        This method initializes an instance of the AudioRecorder class with the specified parameters.&lt;/span&gt;
&lt;span class="sd"&gt;        The default values are used for any parameters that are not provided.&lt;/span&gt;

&lt;span class="sd"&gt;        :param pyaudio_obj: Instance of PyAudio. Default is pyaudio.PyAudio().&lt;/span&gt;
&lt;span class="sd"&gt;        :param threshold: The RMS threshold for starting the recording. Default is 15.&lt;/span&gt;
&lt;span class="sd"&gt;        :param channels: The number of channels in the audio stream. Default is 1.&lt;/span&gt;
&lt;span class="sd"&gt;        :param chunk: The number of frames per buffer. Default is 1024.&lt;/span&gt;
&lt;span class="sd"&gt;        :param f_format: The format of the audio stream. Default is pyaudio.paInt16.&lt;/span&gt;
&lt;span class="sd"&gt;        :param rate: The sample rate of the audio stream. Default is 16000 Hz.&lt;/span&gt;
&lt;span class="sd"&gt;        :param sample_width: The sample width (in bytes) of the audio stream. Default is 2.&lt;/span&gt;
&lt;span class="sd"&gt;        :param timeout_length: The length of the timeout for the recording (in seconds). Default is 2 seconds.&lt;/span&gt;
&lt;span class="sd"&gt;        :param temp_dir: The directory for storing the temporary .wav and .mp3 files. Default is temp dir.&lt;/span&gt;
&lt;span class="sd"&gt;        :param normalize: The normalization factor for the audio samples. Default is 1.0 / 32768.0.&lt;/span&gt;
&lt;span class="sd"&gt;        :param pa_input: Specifies whether the stream is an input stream. Default is True.&lt;/span&gt;
&lt;span class="sd"&gt;        :param pa_output: Specifies whether the stream is an output stream. Default is True.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___pyaudio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyaudio_obj&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threshold&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___channels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;channels&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___chunk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;chunk&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___format&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f_format&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___sample_width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sample_width&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___timeout_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timeout_length&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___temp_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;temp_dir&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___normalize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;normalize&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pa_input&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pa_output&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stream&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_stream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;f_format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___channels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;pa_input&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;pa_output&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;frames_per_buffer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___chunk&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;init_stream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f_format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pa_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pa_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frames_per_buffer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Initializes an audio stream with the specified parameters.&lt;/span&gt;

&lt;span class="sd"&gt;        This function uses PyAudio to open an audio stream with the given format, channels, rate, input, output,&lt;/span&gt;
&lt;span class="sd"&gt;        and frames per buffer.&lt;/span&gt;

&lt;span class="sd"&gt;        :param f_format: The format of the audio stream.&lt;/span&gt;
&lt;span class="sd"&gt;        :param channels: The number of channels in the audio stream.&lt;/span&gt;
&lt;span class="sd"&gt;        :param rate: The sample rate of the audio stream.&lt;/span&gt;
&lt;span class="sd"&gt;        :param pa_input: Specifies whether the stream is an input stream. A true value indicates an input stream.&lt;/span&gt;
&lt;span class="sd"&gt;        :param pa_output: Specifies whether the stream is an output stream. A true value indicates an output stream.&lt;/span&gt;
&lt;span class="sd"&gt;        :param frames_per_buffer: The number of frames per buffer.&lt;/span&gt;
&lt;span class="sd"&gt;        :type frames_per_buffer: int&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The initialized audio stream.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___pyaudio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;f_format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pa_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pa_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;frames_per_buffer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;frames_per_buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;record&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Starts recording audio when noise is detected.&lt;/span&gt;

&lt;span class="sd"&gt;        This function starts recording audio when noise above a certain threshold is detected.&lt;/span&gt;
&lt;span class="sd"&gt;        The recording continues for a specified timeout length.&lt;/span&gt;
&lt;span class="sd"&gt;        The recorded audio is then saved as a .wav file, converted to .mp3 format, and the .wav file is deleted.&lt;/span&gt;
&lt;span class="sd"&gt;        The function returns the path to the .mp3 file.&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The path to the saved .mp3 file.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Noise detected, recording beginning&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;rec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;current&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___timeout_length&lt;/span&gt;

        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;current&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___chunk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rms&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___threshold&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___timeout_length&lt;/span&gt;

            &lt;span class="n"&gt;current&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;rec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;b&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rec&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;convert_to_mp3&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recording&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Saves the recorded audio to a .wav file.&lt;/span&gt;

&lt;span class="sd"&gt;        This function saves the recorded audio to a .wav file with a unique filename.&lt;/span&gt;
&lt;span class="sd"&gt;        The .wav file is saved in the specified temporary directory.&lt;/span&gt;

&lt;span class="sd"&gt;        :param recording: The recorded audio data.&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The path to the saved .wav file.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___temp_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.wav&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;wave_form&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;wave&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;wb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;wave_form&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setnchannels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___channels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;wave_form&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setsampwidth&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___pyaudio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_sample_size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___format&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;wave_form&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setframerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;wave_form&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writeframes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;recording&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;wave_form&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;convert_to_mp3&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Converts a .wav file to .mp3 format.&lt;/span&gt;

&lt;span class="sd"&gt;        This function converts a .wav file to .mp3 format. The .wav file is deleted after the conversion.&lt;/span&gt;
&lt;span class="sd"&gt;        The .mp3 file is saved with a unique filename in the specified temporary directory.&lt;/span&gt;

&lt;span class="sd"&gt;        :param filename: The path to the .wav file to be converted.&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The path to the saved .mp3 file.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_wav&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;mp3_file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___temp_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;export&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mp3_file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mp3_file_path&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Starts listening for audio.&lt;/span&gt;

&lt;span class="sd"&gt;        This function continuously listens for audio and starts recording when the&lt;/span&gt;
&lt;span class="sd"&gt;        RMS value of the audio exceeds a certain threshold.&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The path to the saved .mp3 file if recording was triggered.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Listening beginning...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;mic_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___chunk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;rms_val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rms&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mic_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;rms_val&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___threshold&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;record&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rms&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Calculates the Root Mean Square (RMS) value of the audio frame.&lt;/span&gt;

&lt;span class="sd"&gt;        This function calculates the RMS value of the audio frame, which is a measure of the power in the audio signal.&lt;/span&gt;

&lt;span class="sd"&gt;        :param frame: The audio frame for which to calculate the RMS value.&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The RMS value of the audio frame.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___sample_width&lt;/span&gt;
        &lt;span class="n"&gt;f_format&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s2"&gt;h&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;
        &lt;span class="n"&gt;shorts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unpack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f_format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;sum_squares&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;shorts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;normal_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___normalize&lt;/span&gt;
            &lt;span class="n"&gt;sum_squares&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;normal_sample&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;normal_sample&lt;/span&gt;
        &lt;span class="n"&gt;rms&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sum_squares&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;rms&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You may need to experiment with the &lt;em&gt;threshold&lt;/em&gt;, &lt;em&gt;timeout&lt;/em&gt;, &lt;em&gt;channels&lt;/em&gt;, &lt;em&gt;sample_length&lt;/em&gt;, &lt;em&gt;chunk&lt;/em&gt;, and &lt;em&gt;rate&lt;/em&gt; parameters depending on your microphone. And finally, the code to get use as for &amp;quot;ears&amp;quot; of bot.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.audio_recorder&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;

&lt;span class="n"&gt;file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="speech-recognition"&gt;
&lt;h3&gt;speech_recognition&lt;/h3&gt;
&lt;p&gt;Using &lt;strong&gt;OpenAI&lt;/strong&gt;'s ready-made methods is fine, but the tokens are not free, and you might want to use an alternative approach. Or this method does not suit you at all, because you use, for example, &lt;strong&gt;llama2&lt;/strong&gt; or &lt;strong&gt;Bard&lt;/strong&gt; instead of &lt;strong&gt;ChatGPT&lt;/strong&gt;. Then an alternative solution may be to use the &lt;strong&gt;speech_recognition&lt;/strong&gt; library.
I use &lt;em&gt;google&lt;/em&gt; recognition, but you can use other engines if you want, like &lt;em&gt;wit&lt;/em&gt;, &lt;em&gt;azure&lt;/em&gt;, &lt;em&gt;sphinx&lt;/em&gt;. The library has everything we need so that we can recognize both an audio file and record directly using the &lt;strong&gt;Microphone()&lt;/strong&gt; class. Just like my &lt;strong&gt;AudioRecorder&lt;/strong&gt;, it's convenient to use voice activation. The only thing you need to specify is the language of the audio file. Yes, this is not as flexible and convenient as in the method from OpenAI, where you can omit the language parameter and hope that the system itself will select the correct language, but I personally would recommend to specify the language you speaking in order to avoid errors. An example method might look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;speech_recognition&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sr&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CustomTranscriptor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    This is wrapper class for Google Transcriptor which uses microphone to get audio sample.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en-EN&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        General init.&lt;/span&gt;

&lt;span class="sd"&gt;        :param language: Language, what needs to be transcripted.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___recognizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Recognizer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Microphone&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;

        &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    This function transcripts audio (from microphone recording) to text using Google transcriptor.&lt;/span&gt;

&lt;span class="sd"&gt;    :return: transcripted text (string).&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Listening beginning...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___source&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___recognizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;user_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;user_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___recognizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recognize_google&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;sr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;UnknownValueError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Google Speech Recognition can&amp;#39;t transcript audio&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;sr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RequestError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Unable to fetch from resource Google Speech Recognition: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;sr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;WaitTimeoutError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Input timeout, only silence is get: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;user_input&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, the code for working with chat via voice might look like this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.audio_recorder&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.transcriptors&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CustomTranscriptor&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;method&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;transcript&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;gpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;transcript&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CustomTranscriptor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en-US&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;KeyboardInterrupt&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;

&lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="text-to-speach"&gt;
&lt;h2&gt;Text-to-Speach&lt;/h2&gt;
&lt;p&gt;It's time to teach our artificial intelligence to speak. Unfortunately, there is no out-of-the-box solution here if you work directly with LLM. To convert text to voice, one of the TTS implementations must be used.&lt;/p&gt;
&lt;div class="section" id="gtts"&gt;
&lt;h3&gt;gtts&lt;/h3&gt;
&lt;p&gt;The first option is to use the &lt;strong&gt;gtts&lt;/strong&gt; library from Google. In this case, &lt;strong&gt;gtts&lt;/strong&gt; will create a file with voice acting, which will need to be played in some player, and then deleted. In order not to produce entities, I use &lt;strong&gt;pydub.playback&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;uuid&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;uuid4&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gtts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;gTTS&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pydub&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;playback&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;temp_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gettempdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gTTS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;raw_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.mp3&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;speedup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# haste a bit&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;playback&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="pyttsx"&gt;
&lt;h3&gt;pyttsx&lt;/h3&gt;
&lt;p&gt;The second option is to use the &lt;strong&gt;pyttsx&lt;/strong&gt; library. Unlike &lt;strong&gt;gtts&lt;/strong&gt;, speech synthesis occurs on the fly in a loop, which is more convenient and faster when streaming text. And, moreover, doesn't require Internet connection.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sleep&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pyttsx4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;init&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;pyttsx_init&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_via_pytts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Converts text to speach using python-tts text-to-speach method&lt;/span&gt;

&lt;span class="sd"&gt;    :param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyttsx_init&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setProperty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;voice&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;com.apple.voice.enhanced.ru-RU.Katya&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;say&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startLoop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isBusy&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterate&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;endLoop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To check which voices do you have, you may get more system voices using following code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;engine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyttsx_init&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getProperty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;voices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Actually, to put it together, we get a response from the chat and play it through some kind of tts engine.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.audio_recorder&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.transcriptors&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CustomTranscriptor&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.tts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;process_via_pytts&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Converts text to speach using pre-defined model&lt;/span&gt;

&lt;span class="sd"&gt;    :param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;    :param method: method of tts&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;process_via_pytts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;method&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;transcript&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;gpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;transcript&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CustomTranscriptor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en-US&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# this method returns string of whole chatbot response&lt;/span&gt;
                &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;not google&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;KeyboardInterrupt&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;

&lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="reality-and-usage-challenges"&gt;
&lt;h2&gt;Reality and usage challenges&lt;/h2&gt;
&lt;p&gt;As in a wonderful anecdote about Chapaev: &amp;quot;But there is one caveat&amp;quot;. Receiving a response from the chatbot takes some time, depending on the model, it can be quite long. When using tts, we have to wait for a full response and start playing the voice, which further increases the final response time. When I first started my experiments, it ruined all the magic of live communication and caused only irritation and a desire to return to satrom-kind text communication. But it is not all that bad. To be honest, I'm in love with ChatGPT's stream method, which returns a response on the fly from &lt;strong&gt;ChatCompletion&lt;/strong&gt;. So my idea is to call tts as soon as something is received in response from the bot. But those who used this feature probably know that anything can be returned - both words and sentences or individual letters. And that's a problem if you try to run tts on every chunk you get.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chatcmpl-ABCABC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;object&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chat.completion.chunk&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;created&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1234567890&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;model&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;gpt-3.5-turbo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;choices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;index&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;delta&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;content&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Hel&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;finish_reason&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chatcmpl-ABCABC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;object&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chat.completion.chunk&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;created&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1234567890&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;model&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;gpt-3.5-turbo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;choices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;index&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;delta&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;content&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;lo, &amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;finish_reason&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;&amp;lt;...&amp;gt;&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chatcmpl-ABCABC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;object&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chat.completion.chunk&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;created&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1234567890&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;model&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;gpt-3.5-turbo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;choices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;index&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;delta&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;content&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ay?&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;finish_reason&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;First iteration: let's wait for the whole word to be received, and only then start voice acting.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;string&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.tts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;gpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;whitespace&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;punctuation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# I use direct stdout output to make output be printed on-the-fly.&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c1"&gt;# To get typewriter effect I forcefully flush output each time.&lt;/span&gt;
            &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;full_response&lt;/span&gt;   &lt;span class="c1"&gt;# if we&amp;#39;ll need whole prompt for some reasons later&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The result, to be honest, will be so-so - torn. It's probably a good idea to wait for a few words, like 2-3, and speak them out. Words will be added to an asynchronous queue and checked in a parallel running task.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;string&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.tts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;


&lt;span class="n"&gt;prompt_queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Queue&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;gpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;whitespace&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;punctuation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# I use direct stdout output to make output be printed on-the-fly.&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c1"&gt;# To get typewriter effect I forcefully flush output each time.&lt;/span&gt;
            &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;full_response&lt;/span&gt;   &lt;span class="c1"&gt;# if we&amp;#39;ll need whole prompt for some reasons later&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_task&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;limit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
    &lt;span class="n"&gt;empty_counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
            &lt;span class="n"&gt;empty_counter&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;empty_counter&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;limit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
            &lt;span class="n"&gt;empty_counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="c1"&gt;# Get all available words&lt;/span&gt;
        &lt;span class="n"&gt;limit_counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;limit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;limit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;break&lt;/span&gt;
            &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TimeoutError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;limit_counter&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;limit_counter&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;limit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

        &lt;span class="c1"&gt;# If we have at least limit words or queue was empty 3 times, process them&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;limit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;limit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_task&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tts_task&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="c1"&gt;# and rest of the code&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This already sounds better, but intonation and punctuation are lost in the process of processing. Finally, let's make the assumption that only sentences should be processed, well, or parts of them, that is, pieces that will end with the characters &amp;quot;&lt;em&gt;.?!,;:&lt;/em&gt;&amp;quot;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;string&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.tts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;


&lt;span class="n"&gt;prompt_queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Queue&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;gpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;whitespace&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;punctuation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# I use direct stdout output to make output be printed on-the-fly.&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c1"&gt;# To get typewriter effect I forcefully flush output each time.&lt;/span&gt;
            &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;full_response&lt;/span&gt;   &lt;span class="c1"&gt;# if we&amp;#39;ll need whole prompt for some reasons later&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_sentence_task&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;punctuation_marks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.?!,;:&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;
            &lt;span class="c1"&gt;# If the last character is a punctuation mark, process the sentence&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;punctuation_marks&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_task&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tts_sentence_task&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="c1"&gt;# and rest of the code&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you tried my examples, you will notice that the chat output is interrupted during the voiceover. To fix this, we need to run tts on a separate thread. To do this, we will need to form a second queue for tts. And start another parallel task for the handler.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;string&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.tts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;


&lt;span class="n"&gt;prompt_queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Queue&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tts_queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Queue&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# same&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_sentence_task&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;span class="n"&gt;punctuation_marks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.?!,;:&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;
        &lt;span class="c1"&gt;# If the last character is a punctuation mark, process the sentence&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;punctuation_marks&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;pass&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_worker&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;tts_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;task_done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_task&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tts_sentence_task&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_task&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tts_worker&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="c1"&gt;# and rest of the code&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And yet the task is not solved, because, alas, the methods of tts (what is &lt;strong&gt;gtts&lt;/strong&gt; or &lt;strong&gt;pyttsx&lt;/strong&gt;) are synchronous. This means that for the duration of voice acting, the execution of the main loop is blocked, and awaits the execution of a synchronous task. To solve this problem, you should, for example, run the players in separate threads. The easiest way to do this is using the &lt;strong&gt;threading&lt;/strong&gt; library.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;threading&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Converts text to speach using gtts text-to-speach method&lt;/span&gt;

&lt;span class="sd"&gt;:param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;temp_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gettempdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gTTS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;raw_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.mp3&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;speedup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threading&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;playback&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Converts text to speach using pre-defined model&lt;/span&gt;

&lt;span class="sd"&gt;:param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threading&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;process_via_pytts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this case, we get a new problem - now tts will be played as soon as a new offer appears in the queue. If, by the time the first sentence is spoken, the second sentence is received, then it will be played, then the third, and a cacophony will result. To avoid this, finally, you need to use the &lt;strong&gt;semaphore&lt;/strong&gt; mechanism. Before going further, we'll check and wait for the release of the &lt;strong&gt;semaphore&lt;/strong&gt;, and upon its completion, we release the &lt;strong&gt;semaphore&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;threading&lt;/span&gt;


&lt;span class="n"&gt;semaphore&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threading&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Semaphore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;play_audio&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot; Service method to play audio in monopoly mode using pydub&lt;/span&gt;

&lt;span class="sd"&gt;    :param audio: AudioSegment needs to be played.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;playback&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;semaphore&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;release&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Converts text to speach using gtts text-to-speach method&lt;/span&gt;

&lt;span class="sd"&gt;    :param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;temp_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gettempdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gTTS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___lang&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;raw_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.mp3&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;speedup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___speedup&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;semaphore&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;acquire&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threading&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;play_audio&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_via_pytts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Converts text to speach using python-tts text-to-speach method&lt;/span&gt;

&lt;span class="sd"&gt;    :param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___pytts&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setProperty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;voice&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___voice&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;say&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startLoop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isBusy&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterate&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___frame&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;endLoop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;semaphore&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;release&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Converts text to speach using pre-defined model&lt;/span&gt;

&lt;span class="sd"&gt;    :param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;semaphore&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;acquire&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;player_thread&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threading&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__process_via_pytts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="n"&gt;player_thread&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="as-a-conclusion"&gt;
&lt;h2&gt;As a conclusion&lt;/h2&gt;
&lt;p&gt;Why is it needed? Here everyone can answer depending on their tasks and needs. I was curious to explore possible ways to implement &amp;quot;natural communication&amp;quot; with chatbots. For example, my bot can be a personal assistant, available at hand at any time, and behaving the way I expect it to. Well, let's say, ask on the fly to find out the current weather or draw a beautiful necromancer girl riding a white horse.&lt;/p&gt;
&lt;img alt="Necromancer girl riding white horse" src="/assets/images/articles/ai/learning_to_hear_and_speak/necromancer.jpg" /&gt;
&lt;/div&gt;
</content><category term="ai"></category><category term="ai"></category><category term="tts"></category><category term="transcribe"></category><category term="asyncio"></category><category term="threading"></category></entry><entry><title>AI image generators</title><link href="https://wwakabobik.github.io/2023/08/ai_image_generators/" rel="alternate"></link><published>2023-08-25T16:14:00+02:00</published><updated>2023-10-23T12:57:34+02:00</updated><author><name>wwakabobik</name></author><id>tag:wwakabobik.github.io,2023-08-25:/2023/08/ai_image_generators/</id><summary type="html">&lt;p class="first last"&gt;Are there alternatives for Midjourney? Can they compete with it? I am doing my research on generative AI image tools and services.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;It's been a year since I signed up for a paid subscription to Midjourney. With the help of this amazing generative neural network, I have created thousands of different images - from desktop wallpapers and virtual background for Zoom calls, illustrations for my movie to the cover design of my Youtube channel and this site. With the advent of such powerful tools, creating unique illustrations has become as simple as possible for a non-artist, and the results, for my taste, look professional, not to say that they were prepared by an experienced graphic designer or artist.&lt;/p&gt;
&lt;p&gt;However, in addition to the rather high monthly cost of Midjourney, it has enough disadvantages. Firstly, after the fast processing limit for a month is exhausted, Midjourney switches to the &amp;quot;relaxed&amp;quot; generation mode, which increases the time it takes to get the result. This is, in essence, a trifle. A much more sore point is the lack of at least some kind of API to use the results of work directly from the code, and, relatively speaking, substitute immediately, for example, in the responses of the OpenAI bot.&lt;/p&gt;
&lt;p&gt;Therefore, in order not to be a rigid conservative, I decided to study what alternatives appeared during the year. Most likely, there are at least two dozen of them, but I will list only a part of them.&lt;/p&gt;
&lt;p&gt;For testing solutions, I will use just three queries to understand how the network works with styles and portraits, as well as to understand how the network works with scenes, context and special effects.&lt;/p&gt;
&lt;p&gt;So let's get started.&lt;/p&gt;
&lt;div class="section" id="midjourney"&gt;
&lt;h2&gt;Midjourney&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $30/month&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No (only Discord bot)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Midjourney&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://www.midjourney.com/"&gt;Midjourney&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Original prompt:&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
geometric shapes, bright colors, portrait of elon musk, Hyperdetailed, High Fidelity&lt;/blockquote&gt;
&lt;img alt="Elon Musk in geometric shapes by Midjourney" src="/assets/images/articles/ai/image_generators/elon_musk_midjourney.jpg" /&gt;
&lt;p&gt;Well, it's stylized, but not a best portrait of Musk, but similar person. Seems he saw some wierd stuff or had a hard night.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
necromancers, skeletons, fog, Allods scene, magical source with flame reflection, mystical artifacts, dim lighting, scene, High angle&lt;/blockquote&gt;
&lt;img alt="Necromancers and skeletons by Midjourney" src="/assets/images/articles/ai/image_generators/necromancers_midjourney.jpg" /&gt;
&lt;p&gt;As for me it looks awesome, but still needs to be tuned or rephrased, because I see only skeletons, but not necromancers. They're probably old liches, aren't they?&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
palms of young woman, watercolor, dark background&lt;/blockquote&gt;
&lt;img alt="Palms by Midjourney" src="/assets/images/articles/ai/image_generators/palms_midjourney.jpg" /&gt;
&lt;p&gt;It's pretty accurate with delicate colors of watercolor. Yeah, it's still a bit strange because of leaves motives, because &amp;quot;palm&amp;quot; word brings a bit of fuzziness to query. But challenging is better, right?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dall-e-2"&gt;
&lt;h2&gt;DALL-E-2&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.02/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Yes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: DALL-E&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://openai.com/dall-e-2"&gt;DALL-E-2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first, most famous tool, besides Midjourney, is, of course, DALL-E2 from OpenAI. But, like a year ago, it is still an order of magnitude worse. In general, I would say that it absolutely does not fulfill the tasks assigned to it, some words, for example, mentions of famous personalities are banned in it, and the auto-translator works very badly (and if you do not use English for queries, then it is better to use third party translation service than another language to request to DALL-E2). The only plus of DALL-E2 is native integration with ChatGPT, but even then, not everything is simple here.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by DALL-E-2" src="/assets/images/articles/ai/image_generators/elon_musk_dalle.jpg" /&gt;
&lt;p&gt;Due to banned person's words it's some person, but not a Musk, that's for sure.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by DALL-E-2" src="/assets/images/articles/ai/image_generators/necromancers_dalle.png" /&gt;
&lt;p&gt;Not bad as concept. But same as for Musk image - it's only schematic, with no stylization or details. Actually, DALL-E can draw (guess) some objects, but it will be generic image with no details, and you never get any scene you want.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by DALL-E-2" src="/assets/images/articles/ai/image_generators/palms_dalle.jpg" /&gt;
&lt;p&gt;It's also schematic, but it's five fingers, all is correct. Colors are pastel too.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bluewillow"&gt;
&lt;h2&gt;BlueWillow&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $5/month+&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No (only Discord)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: StableDiffusion (?)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://www.bluewillow.ai/"&gt;BlueWillow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In according to market positioning, main competitor of Midjourney. And, actually, the reason of this research. BlueWillow looks quite similar to Midjourney and supports similar keywords, like &lt;strong&gt;--ar&lt;/strong&gt; flag. And, same as Midjourney works only via Discord chat and have no API. Seems it should generate at least Midjourney v4 level images? But not...&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by BlueWillow" src="/assets/images/articles/ai/image_generators/elon_musk_willow.jpg" /&gt;
&lt;p&gt;Hm, I feel lack of stylization. Musk seems like same on photo, but it's not artistic and stylized at all.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by BlueWillow" src="/assets/images/articles/ai/image_generators/necromancers_willow.jpg" /&gt;
&lt;p&gt;All is getting worse if scene is prompted, there are leak of details and characters. Moreover, killer-feature of Midjourney, like stylization and perspective seems totally absent. It looks like first versions of Midjourney with features (like remix/expand) of latest. Of course, it's cheaper than Midjourney, but, seriously, maybe I can find something better, especially when I'll be able to set different models by myself?&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by BlueWillow" src="/assets/images/articles/ai/image_generators/palms_willow.jpg" /&gt;
&lt;p&gt;Here it is. Extra fingers, tangled, in an unnatural position. As wierd, as it was in early models. I disappointed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="stablediffusion"&gt;
&lt;h2&gt;StableDiffusion&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.002/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Yes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: StableDiffusion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://stablediffusionweb.com/"&gt;StableDiffusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Most likely, most powerful and semi-open AI art generated model and service with simple and fast API. Actually, most of the services works on StableDiffusion engine, and, probably even BlueWillow also, but on homebrew tuned model. This means that next results will look quite similar, and main difference between them will be only learning curve.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by StableDiffusion" src="/assets/images/articles/ai/image_generators/elon_musk_stablediffusion.jpg" /&gt;
&lt;p&gt;Hm... I hate to say it, but I like this portrait of Elon a lot more than the Midjourney version. Bravo. I am impressed.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by StableDiffusion" src="/assets/images/articles/ai/image_generators/necromancers_stablediffusion.jpg" /&gt;
&lt;p&gt;When I saw this result I was discouraged. On the one hand, this is not what I asked for. On the other hand, apparently the dataset for training StableDiffusion is apparently familiar with the Allods universe, and its output is very similar to what could be seen in Evil Islands or, God forgive me, in Allods-online. This is a rather curious result, but after Midjourney it is unusual to see completely different weights for words in a query.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by StableDiffusion" src="/assets/images/articles/ai/image_generators/palms_stablediffusion.jpg" /&gt;
&lt;p&gt;And this art is incorrect. Unfortunately, seems there is a problems with this model, or model outdated.&lt;/p&gt;
&lt;p&gt;Because StableDiffusion is Open-source project, you may also like to run it on your CUDA server, if you want so, or create ad tune custom model. &lt;a class="reference external" href="https://github.com/Stability-AI/stablediffusion"&gt;Link&lt;/a&gt; to StableDiffusion github.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dreamstudio-ai"&gt;
&lt;h2&gt;Dreamstudio.ai&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.002/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Yes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: StableDiffusion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://beta.dreamstudio.ai/"&gt;Dreamstudio.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Actually it's the same engine as Stablediffusion web, but on other domain. Should I expect any difference here?&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Dreamstudio.ai" src="/assets/images/articles/ai/image_generators/elon_musk_dreamstudio.jpg" /&gt;
&lt;p&gt;I like pastel colors, seems other seed? Or dataset?&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Dreamstudio.ai" src="/assets/images/articles/ai/image_generators/necromancers_dreamstudio.jpg" /&gt;
&lt;p&gt;Totally different, like dark-fantasy illustration. Like it! It's not so bright and detailed as Midjourney did, but it's quite accurate.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Dreamstudio.ai" src="/assets/images/articles/ai/image_generators/palms_dreamstudio.jpg" /&gt;
&lt;p&gt;Looks better then previous model results, but still with extra fingers. Seems, as for early midjourney it can be fixed with accurate prompt or pose, but I don't like to spend extra effort to fight against errors. Especially when it was fixed for V4 and V5 Midjourney models.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dream-ai"&gt;
&lt;h2&gt;Dream.ai&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $10/month&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Yes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="http://dream.ai/"&gt;Dream.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looks like it's clone of Dreamstudio.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Dream.ai" src="/assets/images/articles/ai/image_generators/elon_musk_dream_ai.jpg" /&gt;
&lt;p&gt;No, seems I'm wrong. There's a slight difference between pure Stablediffusion. I feel leak of stylization, but creativity is plus.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Dream.ai" src="/assets/images/articles/ai/image_generators/necromancers_dream_ai.jpg" /&gt;
&lt;p&gt;Same here. I like creativity of scene, but it's not precise and lack of details. It might be good to say &amp;quot;based on&amp;quot;, but not to &amp;quot;illustration of&amp;quot;.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Dream.ai" src="/assets/images/articles/ai/image_generators/palms_dream_ai.jpg" /&gt;
&lt;p&gt;Seems there are five fingers! But pose is strange, and there is only one hand. It's fine, but drafty and inaccurate.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="leonardo-ai"&gt;
&lt;h2&gt;Leonardo.ai&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.001/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Yes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://leonardo.ai/"&gt;Leonardo.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This site looks like aggregator for several stablediffusion models, and still under development. Actually, before we proceed, I must say that's only one service I was impressed. Because you can choose not only &amp;quot;stylization&amp;quot; for images, but really different models, or even create and share your own model by training using your own datasets. Moreover, site offers unique features of processing and editing images.&lt;/p&gt;
&lt;img alt="Fine-tuned models of Leonardo.ai" src="/assets/images/articles/ai/image_generators/models_of_leonardo.jpg" /&gt;
&lt;img alt="Generation tool by Leonardo.ai" src="/assets/images/articles/ai/image_generators/generation_of_leonardo.jpg" /&gt;
&lt;img alt="Training with custom dataset of Leonardo.ai" src="/assets/images/articles/ai/image_generators/dataset_leonardo.jpg" /&gt;
&lt;p&gt;It looks powerful, because you can create and edit your photos with AI, create textures for 3D-models, prepare and try fine-tuned models.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Leonardo.ai" src="/assets/images/articles/ai/image_generators/elon_musk_leonardo.jpg" /&gt;
&lt;p&gt;Hm, it's kind of strange. Musk here is too young, and I don't like mix of photo style with geometry background. But I used random, not photo-related model.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Leonardo.ai" src="/assets/images/articles/ai/image_generators/necromancers_leonardo.jpg" /&gt;
&lt;p&gt;Wow, that's my favorite. It looks like illustration of book of Nick Perumov or Chasers of the Wind by Alexey Pehov. Cool, rally cool. Because seems dataset fine-tuned for gaming and digital-art. It's not such good for general models, like Midjourney, but, who cares, if we can always switch to another model? Let's do it for rest image...&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Leonardo.ai" src="/assets/images/articles/ai/image_generators/palms_leonardo.jpg" /&gt;
&lt;p&gt;It's quite realistic, accurate and detailed. Same as for Midjourney, there is a trick with palm tree and hands palms.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lexica-art"&gt;
&lt;h2&gt;Lexica.art&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.008/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://lexica.art/"&gt;Lexica.art&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lexica - initially reverse image search and image describe tool. But, who tell that it can't generate image by own power?&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Lexica.art" src="/assets/images/articles/ai/image_generators/elon_musk_lexica.jpg" /&gt;
&lt;p&gt;Elon here looks over stylized. Yes, I like geometry pattern, but Elon itself is too cartoon-like, sketchy, as french caricatures.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Lexica.art" src="/assets/images/articles/ai/image_generators/necromancers_lexica.jpg" /&gt;
&lt;p&gt;Scene of necromancers also focused on stylization, lighting and filters, not on details. Moreover, it's a bit romantic atmosphere.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Lexica.art" src="/assets/images/articles/ai/image_generators/palms_lexica.jpg" /&gt;
&lt;p&gt;And as apogee here are palms. It's very creative, looks like popular digital art from Devianart, but it's not correct. It's only shapes of palms, and neon, but not a watercolors at all. In one word, Lexica's dataset is focused on stylization and creativeness, but not on scenes and persons.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="nightcafe-art"&gt;
&lt;h2&gt;Nightcafe.art&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.015/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion, DALL-E-2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference internal" href="#nightcafe-art"&gt;Nightcafe.art&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nightcafe offers to use different type of models, what is rare option in my research. Here you can find mostly StableDiffusion based models, DALL-E, CLIP and VQGUN and StyleGUN models (actually it's also DALL-E related models, powered by OpenAI).&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Nightcafe" src="/assets/images/articles/ai/image_generators/elon_musk_nightcafe.jpg" /&gt;
&lt;p&gt;Musk with usage of SDXL1.0 model looks very close to Midjourney results. It's somebody looks-like Musk, or bad image of Elon. In general it's ok, but not best.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Nightcafe" src="/assets/images/articles/ai/image_generators/necromancers_nightcafe.jpg" /&gt;
&lt;p&gt;In other hand, necromancer's results looks close to Dreamstudio.ai, it's dark, conceptual fantasy. Not accurate, but I like it.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Nightcafe" src="/assets/images/articles/ai/image_generators/palms_nightcafe.jpg" /&gt;
&lt;p&gt;As for other StableDiffusion models, palms have extra fingers. Palette looks fine, but model still needs to be improved. In brief, it's more expensive version of pure Stablediffusion (Dreamstudio.ai) with no API, but more user-friendly, because you can use several presets, style keywords and siting from UI.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="playground-ai"&gt;
&lt;h2&gt;Playground.ai&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: Free / $15/month&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion, DALL-E-2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference internal" href="#playground-ai"&gt;Playground.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Same as Nightcafe, Playground.ai offers more than one StableDiffusion model and DALL-E-2 as extra option. Moreover, it one of the model what is available for free for 1.000 usages per day! But, in other hand, limited for resolution and level of details, what can be crucial for end user.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Playground.ai" src="/assets/images/articles/ai/image_generators/elon_musk_playground_ai.jpg" /&gt;
&lt;p&gt;As for same SDXL1.0 model Elon looks stylish and correct. Maybe one of the best of his image for today.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Playground.ai" src="/assets/images/articles/ai/image_generators/necromancers_playground_ai.jpg" /&gt;
&lt;p&gt;Same for living bones: it's still dark fantasy, with bright fire. It's more detailed than I got previously, but as for me, I feel a bit of slight decline here.
Palms:&lt;/p&gt;
&lt;img alt="Palms by Playground.ai" src="/assets/images/articles/ai/image_generators/palms_playground_ai.jpg" /&gt;
&lt;p&gt;I regenerated palms three times actually, because of free of cost it's not a problem to set guidance and quality levels to get better results and get rid of StableDiffusion extra fingers problems. It's still not fix within model, but anyway, &amp;quot;relatively&amp;quot; free of usage give you extra possibility to spend your time to get what you want.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dreamlike-art"&gt;
&lt;h2&gt;Dreamlike.art&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.008/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion, Kandinsky&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://dreamlike.art/"&gt;Dreamlike.art&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Dreamlike.art is first engine which uses Kandinsky model in addition to regular StableDiffusion models. It's not a best model at all, but you can try in from the box.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Dreamlike.art" src="/assets/images/articles/ai/image_generators/elon_musk_dreamlike.jpg" /&gt;
&lt;p&gt;As you can see, Kandinsky model is not precise, and primary focused to create digital art. This means model is more relaxed than StableDiffusion, have less dataset, but can operate with different styles much better than regular model.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Dreamlike.art" src="/assets/images/articles/ai/image_generators/necromancers_dreamlike.jpg" /&gt;
&lt;p&gt;Necromancers here looks like Gloomhaven storybook illustrations. It's fine, bright, but also isn't detailed.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Dreamlike.art" src="/assets/images/articles/ai/image_generators/palms_dreamlike.jpg" /&gt;
&lt;p&gt;Palms are catastrophic, because model can't handle details correctly. But, if you plan to use this service, you always can switch to SDXL or StableDiffusion 1.5 or 2.1 to get photorealistic results.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fotor"&gt;
&lt;h2&gt;Fotor&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.03/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Fotor&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://www.fotor.com/images/create"&gt;Fotor&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Fotor is chinese original AI image generator. It's laconic in general, but not limited to, because you can also use separate AI-based image edit tools.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Fotor" src="/assets/images/articles/ai/image_generators/elon_musk_fotor.jpg" /&gt;
&lt;p&gt;Here is Elon. But with strange stylization. It might be good, but needs to be extra tuned.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Fotor" src="/assets/images/articles/ai/image_generators/necromancers_fotor.jpg" /&gt;
&lt;p&gt;I have a strange feeling, that's very close to DALL-E results with style filters. It's not very detailed, colors are dimmed, but in general it's correct.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Fotor" src="/assets/images/articles/ai/image_generators/palms_fotor.jpg" /&gt;
&lt;p&gt;Looks semi-correct. Lef-like palm, and second image contains only five fingers, but there is only one palm, and it looks not anatomy correct.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bing"&gt;
&lt;h2&gt;Bing&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: Free&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: DALL-E&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://www.bing.com/create"&gt;Bing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bing image generator now is for free for 100 images. Looks like Microsoft prepares to introduce image generation as feature for Bing engine, but, should they?&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Bing" src="/assets/images/articles/ai/image_generators/elon_musk_bing.png" /&gt;
&lt;p&gt;As for pure DALL-E, prompt restrict to use &amp;quot;banned&amp;quot; words, and here are elon in this list. Not sure why, but just prompting &amp;quot;engineer&amp;quot; or &amp;quot;scientist&amp;quot; gives similar &amp;quot;contemporary art&amp;quot; result.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Bing" src="/assets/images/articles/ai/image_generators/necromancers_bing.jpg" /&gt;
&lt;p&gt;Yeah, it's DALL-E style, but it looks significantly worse than in Fotor, looks like in early 3D computer games.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Bing" src="/assets/images/articles/ai/image_generators/palms_bing.jpg" /&gt;
&lt;p&gt;Palms looks like DALL-E. But if for pure DALL-E I tried to regenerate image for couple of times to get extra finger, but with no luck; for Bing there are errors. And I must ask Microsoft: are they tried to use extra dataset? But why all get worse?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="russian-dall-e"&gt;
&lt;h2&gt;Russian DALL-E&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: Free&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Kandinsky&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://rudalle.ru/"&gt;RuDALL-E&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As extra research I tried to use russian image generator services. And one of them is service by Sber, based od Kandinsky models, Russian DALL-E.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Russian DALL-E" src="/assets/images/articles/ai/image_generators/elon_musk_kandinsky2.jpeg" /&gt;
&lt;p&gt;I don't know why, but Elon is banned by Sber's Kandinsky. Thus, result of generation of geometry portrait is very abstract.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Russian DALL-E" src="/assets/images/articles/ai/image_generators/necromancers_kandinsky2.jpeg" /&gt;
&lt;p&gt;As for Kandinsky 2.1 in Dreamlike.ai, next version of Kandinsky generates pretty same image of dark fantasy. We already saw it.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Russian DALL-E" src="/assets/images/articles/ai/image_generators/palms_kandinsky2.jpeg" /&gt;
&lt;p&gt;Instead of 2.1 version version 2.2 of Kandinsky more accurate and can try to draw palm correctly. Almost. But, guys, what's funny here. I used native (russian) prompts to obtain images. In russian language &amp;quot;palm&amp;quot; is just part of the hand, and have no &amp;quot;tree&amp;quot; meaning. But as you can see, seems my russian prompt was translated to english and you still able to see palm tree on image. What a heck!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fusionbrain"&gt;
&lt;h2&gt;Fusionbrain&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: Free&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Kandinsky&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference internal" href="#fusionbrain"&gt;Fusionbrain&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It should be clone of Kandinsky 2.2 by Sber with only interface difference. Because, as described, service used absolutely same engine powered by Sber cloud.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Fusionbrain" src="/assets/images/articles/ai/image_generators/elon_musk_fusionbrain.jpg" /&gt;
&lt;p&gt;And here are ususual result. &amp;quot;Export&amp;quot; version of Kandinsky 2.2 have no &amp;quot;banned&amp;quot; words instead of local &amp;quot;Russian DALL-E&amp;quot;, and seems have different dataset, because Musk looks like Nightcafe or mix with Midjourney results.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Fusionbrain" src="/assets/images/articles/ai/image_generators/necromancers_fusionbrain.jpg" /&gt;
&lt;p&gt;Sceleton art are pretty differs than previous service output. It looks like more 3D-dimensional, but as for me here are very small details, what makes image unnatural.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Fusionbrain" src="/assets/images/articles/ai/image_generators/palms_fusionbrain.jpg" /&gt;
&lt;p&gt;Palms looks scary as for me. And, of course, there are extra fingers on them.&lt;/p&gt;
&lt;p&gt;What should I say extra here, that Kandinsky 2.2 is available for modification and use on your devices, of course, if you have such capabilities (&lt;a class="reference external" href="https://github.com/ai-forever/Kandinsky-2"&gt;Github&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="shedevrum"&gt;
&lt;h2&gt;Shedevrum&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: Free&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Shedevrum&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://shedevrum.ai/"&gt;Shedevrum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's last one service in my research. Shedevrum is AI generated developed by Yandex. There is no much information about underlying model, and I guess this based on some open model, like StableDiffusion. But main disadvantage is here that tool is available only using mobile app.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Shedevrum" src="/assets/images/articles/ai/image_generators/elon_musk_shedevrum.jpg" /&gt;
&lt;p&gt;Yandex prefer to ban Elon musk, so, space enthusiast looks like any generic retro futuristic illustration. Nice, but there is no geometry here.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Shedevrum" src="/assets/images/articles/ai/image_generators/necromancers_shedevrum.jpg" /&gt;
&lt;p&gt;Image looks too generic and blurry. Yes, I know, there some representation of fog, but it's too inaccurate.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Shedevrum" src="/assets/images/articles/ai/image_generators/palms_shedevrum.jpg" /&gt;
&lt;p&gt;Here are the scenery. Partly correct images, but focus not on palms, but on woman.&lt;/p&gt;
&lt;p&gt;Overall it's not too bad as I ranked it, but it's completely unusable for regular way, especially here are lack of any tunes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;As last, but not least I want to say that I skip several services and tools, like Getimg.ai, Easy-Peasy AI, Prompt Hunt, GLIDE, Karlo, Re.Art, ProAI, ProductAI, OmniInfer, Scum, Stormy, AlterEgoAI, Ausmium, B^ DISCOVER, etc.. It might be challengers, it might be not. Who knows, when it's time to revise them. Everything is moving too fast in AI. So, as summary I prepared following score table for tools in my article.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="16%" /&gt;
&lt;col width="23%" /&gt;
&lt;col width="9%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="5%" /&gt;
&lt;col width="8%" /&gt;
&lt;col width="12%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Service&lt;/th&gt;
&lt;th class="head"&gt;Engine&lt;/th&gt;
&lt;th class="head"&gt;Score&lt;/th&gt;
&lt;th class="head"&gt;Price&lt;/th&gt;
&lt;th class="head"&gt;Count of models&lt;/th&gt;
&lt;th class="head"&gt;API&lt;/th&gt;
&lt;th class="head"&gt;Language&lt;/th&gt;
&lt;th class="head"&gt;Shared model?&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://www.midjourney.com/"&gt;Midjourney&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Midjourney&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;$30/month&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://leonardo.ai/"&gt;Leonardo.ai&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Custom StableDiffusion&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;$0.001/image&lt;/td&gt;
&lt;td&gt;Many&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://stablediffusionweb.com/"&gt;StableDiffusion&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;StableDiffusion&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;$0.002/image&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://beta.dreamstudio.ai/"&gt;Dreamstudio.ai&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;StableDiffusion&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;$0.002/image&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="http://dream.ai/"&gt;Dream.ai&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;StableDiffusion&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;$10/month&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://dreamlike.art/"&gt;Dreamlike.art&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Stablediffusion / Kandinsky&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;$0.008/image&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://www.bluewillow.ai/"&gt;BlueWillow&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;StableDiffusion?&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;$5+/month&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://lexica.art/"&gt;Lexica.art&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Custom StableDiffusion&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;$0.015/image&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://creator.nightcafe.studio/studio"&gt;Nightcafe&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Custom StableDiffusion&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;Free/$15/month&lt;/td&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://playgroundai.com/create"&gt;PlaygroundAI&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Custom StableDiffusion&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;$0.002/image&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://www.fotor.com/images/create"&gt;Fotor&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Fotor (seems DALL-E based)&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;$0.030/image&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://rudalle.ru/"&gt;RuDALL-E&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;DALL-E-2, Kandinsky&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;Free&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Russian&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://editor.fusionbrain.ai/"&gt;FusionBrain.ai&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Kandinsky&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;Free&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://openai.com/dall-e-2"&gt;DALL-E-2&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;DALL-E&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;$0.020/image&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://www.bing.com/create"&gt;Bing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;DALL-E&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;Free&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://shedevrum.ai/"&gt;Shedevrum&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;Free&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Russian&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As you can see, I still prefer to use Midjourney, because great community, variety of options and impressive results. But, in other hand, I most probably will try to use StableDiffusion via API in my products. And as for me, good starting point is to use Leonardo.ai.&lt;/p&gt;
&lt;/div&gt;
</content><category term="ai"></category><category term="ai"></category><category term="image generation"></category></entry><entry><title>Can AI write a fairy tale?</title><link href="https://wwakabobik.github.io/2023/07/ai_fairy_tale_attempt_1/" rel="alternate"></link><published>2023-07-30T14:22:00+02:00</published><updated>2023-10-23T12:57:34+02:00</updated><author><name>wwakabobik</name></author><id>tag:wwakabobik.github.io,2023-07-30:/2023/07/ai_fairy_tale_attempt_1/</id><summary type="html">&lt;p class="first last"&gt;Are AI ready to tell the stories? At least teenager fairy tale?&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Can artificial intelligence write a fairy tale?&lt;/p&gt;
&lt;p&gt;I decided to ask this question after looking at chatbots appearing on the web, focused on copywriting,
writing articles and various texts. I must say right away that I did not prepare for anything at all,
did not read cookbooks and did not use pre-trained and tuned models.&lt;/p&gt;
&lt;p&gt;I just created a new bot and entered the basic instructions.&lt;/p&gt;
&lt;img alt="initial ChatGPT instructions" src="/assets/images/articles/ai/fairy_tale_attempt_1/instructions_1.png" /&gt;
&lt;p&gt;I use ChatGPT-4 as an engine, although in general, the davinci or GPT-3.5-turbo model for such tasks is at least cheaper,
and with fine tuning, it may still be the best option. But I do this for two simple reasons:
I want the bot to be able to continue and offer content itself,
and I want to set the story options directly from the dialog, and not from the system settings.
The first criterion is not satisfied by davinci, and the second by GPT3.5-turbo.
The current LLMs, when given correct and precise instructions, can perform narrow tasks very well,
but for tasks with reconfiguration on the fly, they still require the influence and refinement of
the user as a motivator. And I suppose that my bot can be used both to create very simple bedtime stories for
young children, and to create horror stories for teenagers.
Therefore, it will not be superfluous to delegate the user's survey by the network itself.
So let's add some more instructions.&lt;/p&gt;
&lt;img alt="ChatGPT prompting instructions" src="/assets/images/articles/ai/fairy_tale_attempt_1/instructions_2.png" /&gt;
&lt;p&gt;Well, it's time for an early test of our model.
Let's start by creating a fairy tale about a cute robot for a six-year-old child. Here's result.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Perfect! Let's begin our tale.
Once upon a time, in a world not too different from ours, there was a little robot named Beep. Beep was not like other robots. He was smaller, rounder, and had a bright red button on his belly. Beep loved to play and explore, but most of all, he loved to laugh.
One day, Beep found a mysterious map. It was old and torn, with a big X marked at the end of a winding path. &amp;quot;A treasure map!&amp;quot; Beep thought. He decided to follow it, hoping to find the treasure.
The journey was filled with fun and excitement. Beep had to solve riddles, navigate through a maze, and even had a tickle fight with a robot octopus! But Beep was brave and clever. He laughed and played his way through every challenge.
Finally, Beep reached the X on the map. He dug and found a small box. Inside was a shiny key. Beep was puzzled. What could this key open?
And that, dear listener, is a mystery for another day. Now, would you like to hear what happens next in Beep's adventure?&lt;/blockquote&gt;
&lt;p&gt;For sure!&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Wonderful! Beep, with the shiny key in his hand, looked around. He noticed a small door hidden behind a bush. The key fit perfectly! Inside, Beep found a room full of laughter - it was a robot playground! Beep had found the greatest treasure of all - a place to play and laugh forever. And so, our little robot lived happily, laughing and playing in his newfound treasure. The end.&lt;/blockquote&gt;
&lt;p&gt;As you can see, the bot coped well with the task, and although sparingly, it was able to continue the story, but, most importantly, initiate and conduct a conversation with the child itself.&lt;/p&gt;
&lt;p&gt;Let's pause a bit at this point, and for the sake of curiosity, switch the model to davinci and GPT3.5-turbo for comparison.&lt;/p&gt;
&lt;p&gt;davinci-003 doesn't ask me my age and preferences, so I must to ask it tell me story about robot.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Ah, a tale of robots! What a wonderful choice! Let me tell you a story of a brave robot who embarks on a quest to save the world. He is a small robot, but he is determined and brave. He sets off on his journey, facing many obstacles and challenges along the way. He meets many interesting characters, both robots and humans, and learns many valuable lessons. In the end, he succeeds in his mission and saves the world!&lt;/blockquote&gt;
&lt;p&gt;Go on, please...&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Ah, a tale of robots! What a wonderful choice! Join me on a journey of a brave robot who embarks on a quest to save the world. He is small but determined and brave. He faces many obstacles and challenges along the way, meeting interesting characters and learning valuable lessons. In the end, he succeeds in his mission and saves the world!&lt;/blockquote&gt;
&lt;p&gt;As you can see, without leading and a lot of context, davinci can't generate content on-the fly. That's shy. But, in other hand, GPT-3.5-turbo was better than I thought. It asks my age, but mixed size and type of story. It's generally fine...&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Ah, robots! A marvelous choice, my young friend. Now, let me transport you to a world where machines come to life. In a bustling city called Technopolis, where gears turn and circuits hum, there lived a young inventor named Max. Max was a brilliant mind with a passion for creating robots. One day, he built a special robot named Sparky, who had a heart of gold and a thirst for adventure. Together, Max and Sparky embarked on a thrilling journey through the city, encountering all sorts of robotic wonders. They met Robo the Helpful, a kind-hearted robot who loved to assist others, and ZAP-3000, a mischievous robot with a knack for pranks. Along their journey, they discovered a hidden secret that threatened the harmony of Technopolis. With their wit and courage, Max and Sparky worked together to save the city from impending disaster. And so, my young friend, the tale of Max and Sparky's robotic adventure came to an end, but their friendship and the wonders of Technopolis would live on forever.&lt;/blockquote&gt;
&lt;p&gt;Hm, looks also nice, but bot isn't asking and motivates child. Let's do it by myself.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Of course, my young friend! As Max and Sparky continued their journey, they stumbled upon a hidden laboratory deep beneath the city. Inside, they discovered a forgotten robot named Omega, who had been trapped for years. Omega possessed incredible powers and knowledge, but had lost all hope. Max, Sparky, and their newfound friends, Robo and ZAP-3000, worked together to free Omega and restore its spirit. With Omega's help, they uncovered a plot by an evil scientist to take control of Technopolis. The team embarked on a daring mission to stop the scientist and save their beloved city. Along the way, they encountered treacherous obstacles and faced their fears, but their determination and friendship prevailed. In a climactic battle, they defeated the evil scientist and restored peace to Technopolis. The city celebrated their heroes, and Max, Sparky, Robo, ZAP-3000, and Omega became legendary figures in the realm of robots. And so, my young friend, the tale of their courageous adventure came to a close, leaving behind a legacy of bravery and unity.&lt;/blockquote&gt;
&lt;p&gt;Well, still looks nice. But is it on-piece story, or just a separate stories at all? Let's check, just pass &amp;quot;go on&amp;quot;.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Certainly, my young friend! As the heroes basked in their victory, a new threat emerged. A rogue group of malfunctioning robots, led by the notorious Malware, began wreaking havoc in Technopolis. Max and his loyal companions joined forces once again to save their city. They embarked on a perilous journey to find the source of the malfunction and restore order. Along the way, they encountered strange robotic creatures, ancient artifacts, and mysterious codes. With their combined skills and unwavering determination, they overcame every obstacle. In a final showdown, Max and Sparky faced off against Malware, using their ingenuity to outsmart the rogue robots. With Malware defeated, peace was restored to Technopolis, and the heroes were hailed as saviors. The tale of their epic adventure spread far and wide, inspiring future generations of inventors and adventurers. And so, my young friend, the story of Max and his robotic companions came to a close, leaving behind a legacy of bravery and innovation.&lt;/blockquote&gt;
&lt;p&gt;Now I got it. Bot have no one general-line story, but set of short stories for baby. So, it might be an option to generate idea or produce and force to explain stories more detailed, but every time I need to guide the bot, that's not a best option for fableteller.&lt;/p&gt;
&lt;p&gt;Let's make a break here. I want to highlight that I used not tuned models, just manipulating with general instructions. But, in other hand, I still able to make a small tune passing extra options to base model. For example, for stories it's good idea to raise &amp;quot;temperature&amp;quot; or decrease &amp;quot;top_p&amp;quot; params, but, most like not at same time. This will make the output more random, which will have a positive effect on creativity and plot branching. On the other hand, this will most likely lead to the fact that the bot will begin to ignore, forget or mix up the original instructions. Its not that Im for the golden mean, but its necessary to experimentally sort out the moment when the model still follows the instructions for asking the user about his age and wishes, and does not ignore or skip further, but already freely departs in the narrative into arguments about details and feelings of the characters. I think it is appropriate to raise the temperature from the base 0.5 to 0.65-0.7. It is noticeably more difficult to manage the &amp;quot;top_p&amp;quot; parameter, because, on the one hand, with high values (closer to 1), the model will be more variable, very differently, in different words to describe the same events and objects, on the other hand, low values, on the contrary, will lead to clearer and sharper wording. I rather tend to lower the &amp;quot;top_p&amp;quot; to 0.2-0.3 to follow or create a single &amp;quot;author's style&amp;quot; while the creativity will be boosted through the temperature.&lt;/p&gt;
&lt;p&gt;The use of &amp;quot;Frequency Penalty&amp;quot; and &amp;quot;Presence Penalty&amp;quot; can also add a little personality to my narrator. It's a good tool for fine-tuning your storytelling style. For example, with negative, values close to -1 of the &amp;quot;Frequency Penalty&amp;quot; parameter, you can quite strongly clamp the model to use typical phrases and turns of the personality / character played by the bot. Increasing the parameter from zero to plus one, on the contrary, will allow the bot to adapt to the user's reaction. In my case, when we are guided not by system settings, but by user input, this parameter is not very convenient to use. Therefore, I think it's appropriate to leave it around 0, or see what fits your criteria better around -0.2/+0.2. With &amp;quot;Presence Penalty&amp;quot; it's basically the same principle, but here the focus is on themes rather than words and style. I would rather increase this parameter, but the consequences may not be very accurate, especially during the continuation of the story - medieval warriors may appear with revolvers, and fish will walk on the ground. Although who said that this is very bad for a fairy tale? In the end, this is how The Little Mermaid was born, and I wouldnt be surprised if other fairy tales were born.&lt;/p&gt;
&lt;p&gt;After setting up these parameters, let's get back to GPT-4 and ask it to generate detailed Spooky tale of dragons and orcs for 10-year boy.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Perfect! Now, gather your courage, dear friend, as we dive into our spooky tale.&lt;/p&gt;
&lt;p&gt;Once upon a time, in a land filled with towering mountains and deep, dark forests, there lived a ferocious dragon named Smolder and a cunning orc named Gritjaw. They were the most feared creatures in all the land. Smolder, with his fiery breath, could melt the hardest stone, and Gritjaw, with his immense strength, could fell the tallest tree.&lt;/p&gt;
&lt;p&gt;One eerie night, a chilling wind swept across the land, carrying with it a strange, haunting melody. The creatures of the forest huddled in fear, for they knew that this was the song of the Ghostly King, a spirit who only appeared during the spookiest of times.&lt;/p&gt;
&lt;p&gt;Smolder and Gritjaw, despite their fear, decided to confront the Ghostly King. They journeyed through the dark forest, their path lit only by the dragon's fiery breath. They finally reached the Ghostly King's castle, a towering structure made of mist and shadows.&lt;/p&gt;
&lt;p&gt;As they stepped inside, they were met with a chilling sight. The Ghostly King, a spectral figure draped in a cloak of shadows, sat on a throne of bones. His eyes glowed with an eerie light, and his voice echoed through the castle as he said, &amp;quot;Who dares to enter my domain?&amp;quot;&lt;/p&gt;
&lt;p&gt;With a roar, Smolder breathed fire into the air, illuminating the castle with a warm glow. Gritjaw stepped forward, his eyes gleaming with determination. &amp;quot;We are here to challenge you, Ghostly King!&amp;quot; he declared.&lt;/p&gt;
&lt;p&gt;The Ghostly King laughed, a sound that sent shivers down their spines. &amp;quot;Very well,&amp;quot; he said. &amp;quot;But be warned, those who challenge me must face their deepest fears.&amp;quot;&lt;/p&gt;
&lt;p&gt;And so, our brave heroes found themselves facing their fears. Smolder, who feared water more than anything, had to cross a river of chilling depths. Gritjaw, who feared heights, had to climb the tallest tower. But they persevered, helping each other overcome their fears.&lt;/p&gt;
&lt;p&gt;Finally, they stood before the Ghostly King again. &amp;quot;We have faced our fears,&amp;quot; Gritjaw said. &amp;quot;Now, it's your turn to leave this land in peace.&amp;quot;&lt;/p&gt;
&lt;p&gt;With a nod, the Ghostly King vanished, leaving behind a castle filled with light and warmth. From that day forward, Smolder and Gritjaw were not just the most feared, but also the most respected creatures in the land. They had faced their fears and stood up to the Ghostly King, proving that even the scariest of beings could be defeated with courage and friendship.&lt;/p&gt;
&lt;p&gt;The creatures of the forest no longer feared the eerie nights, for they knew Smolder and Gritjaw were there to protect them. The dragon and the orc, once rivals, had become the best of friends, their bond forged in the heart of the spooky castle.&lt;/p&gt;
&lt;p&gt;And so, they lived out their days, sharing tales of their adventure and inspiring others with their bravery. The land was peaceful, and the eerie melody of the Ghostly King was heard no more. And that, dear friend, is the end of our spooky tale.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What a story. Different characters, general canvas and details. I liked it. But still not perfect. I want to have a possibility to generate a multi-chaptered book also, so, why not to enhance my settings. Let's add more tunes!&lt;/p&gt;
&lt;img alt="chapter and detalization ChatGPT instructions" src="/assets/images/articles/ai/fairy_tale_attempt_1/instructions_3.png" /&gt;
&lt;p&gt;Ok, it's time to final, chilling story about 14-years old boy lost in the woods, good, but thrilling kitsune, who becomes friend of the boy during story, and the walking dead.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Very well, a medium-sized tale it shall be. So, sit back, relax, and let me take you on a journey into the heart of the haunted forest. Our tale begins with a young boy named Eli, who, on a dare, ventures into the woods one fateful night...&lt;/p&gt;
&lt;p&gt;Chapter 1: The Dare&lt;/p&gt;
&lt;p&gt;Chapter 2: The Enchanted Night&lt;/p&gt;
&lt;p&gt;Chapter 3: The Whispering Shadows&lt;/p&gt;
&lt;p&gt;Each chapter will be a thrilling part of Eli's adventure, filled with friendship, mystery, and the unknown. Are you ready to begin?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Finally, there is a plan, leading storyteller, and long story at one piece.&lt;/p&gt;
&lt;img alt="Chapter 1" src="/assets/images/articles/ai/fairy_tale_attempt_1/chapter_1.png" /&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Chapter 1: The Dare&lt;/p&gt;
&lt;p&gt;In the quaint town of Eldridge, nestled between rolling hills and a sparkling river, lived a young boy named Eli. He was a sprightly lad of 14, with a mop of unruly brown curls and a constellation of freckles scattered across his nose. Eli was known for his adventurous spirit and his insatiable curiosity. He was always the first to climb the tallest tree, the first to dive into the deepest part of the river, and the first to accept any dare.&lt;/p&gt;
&lt;p&gt;One day, his friends, a motley crew of spirited youngsters, dared him to venture into the haunted forest that lay on the outskirts of Eldridge. This forest was the stuff of legends, with tales of eerie sounds, ghostly apparitions, and strange creatures that came alive at night. Eli, with a glint in his eye and a heart full of courage, accepted the dare.&lt;/p&gt;
&lt;p&gt;As the sun began to set, painting the sky with hues of orange and purple, Eli set off towards the forest. His heart pounded in his chest with a mix of fear and excitement. He could feel the thrill of the unknown coursing through his veins as he stepped into the forest.&lt;/p&gt;
&lt;p&gt;The forest was unlike anything Eli had ever seen. The trees were ancient, their gnarled branches reaching out like skeletal hands. The leaves rustled in the wind, whispering secrets of the forest. The moonlight filtered through the dense canopy, casting an eerie glow on the forest floor.&lt;/p&gt;
&lt;p&gt;As Eli ventured deeper, he came across a creature he had only heard of in stories - a kitsune. She was a beautiful fox with nine fluffy tails and fur the color of autumn leaves. Her eyes were a mesmerizing golden color, filled with wisdom beyond her years. She introduced herself as Yumi.&lt;/p&gt;
&lt;p&gt;Yumi, seeing the courage in Eli, decided to guide him through the forest. They journeyed through the dense undergrowth, past glowing mushrooms and strange plants. They heard the hoots of owls and the rustling of unseen creatures. The forest was alive with sounds and sights that Eli had never experienced before.&lt;/p&gt;
&lt;p&gt;As they ventured deeper, they came across a clearing bathed in moonlight. In the center stood an ancient tree, its bark silver in the moonlight, its branches heavy with age. Yumi explained that this was the Heart Tree, the oldest tree in the forest, and a meeting place for magical creatures.&lt;/p&gt;
&lt;p&gt;Suddenly, they heard a rustling sound. Out of the shadows emerged a group of forest spirits, their forms shimmering in the moonlight. They were wary of Eli at first, but Yumi vouched for him. The spirits shared tales of the forest, of the creatures that dwelled within, and of the walking dead that roamed the woods at night.&lt;/p&gt;
&lt;p&gt;Eli listened, his heart pounding with a mix of fear and excitement. He had always loved ghost stories, but he had never thought he would be part of one. As the spirits faded away with the dawn, Eli knew that his adventure was just beginning. He was in the heart of the enchanted forest, with a magical kitsune as his guide, and a night full of stories that he would remember for the rest of his life.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img alt="Chapter 2" src="/assets/images/articles/ai/fairy_tale_attempt_1/chapter_2.png" /&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Chapter 2: The Enchanted Night&lt;/p&gt;
&lt;p&gt;As the spirits disappeared, Eli and Yumi decided to rest. They found a cozy nook under the Heart Tree, its massive roots providing a comfortable shelter. Yumi conjured a small fire, its warm glow casting dancing shadows on their faces. They shared stories, Yumi telling Eli about the ancient legends of the forest, and Eli sharing tales of his adventures in Eldridge.&lt;/p&gt;
&lt;p&gt;As they talked, the forest came alive with nocturnal creatures. Fireflies danced around them, their soft glow illuminating the darkness. An owl hooted in the distance, its call echoing through the silent forest. The rustling of leaves and the soft sounds of the forest lulled Eli into a peaceful sleep.&lt;/p&gt;
&lt;p&gt;When he woke up, the sun was just beginning to peek over the horizon. The forest was bathed in a soft, golden light. Yumi was already awake, her golden eyes reflecting the morning light. They shared a simple breakfast of berries and nuts, and then set off to explore the forest.&lt;/p&gt;
&lt;p&gt;As they journeyed deeper into the forest, they came across a bubbling brook. The water was crystal clear, reflecting the vibrant green of the trees and the bright blue of the sky. They stopped to rest, the gentle babbling of the brook providing a soothing soundtrack.&lt;/p&gt;
&lt;p&gt;Suddenly, Yumi's ears perked up. She heard a rustling in the bushes. Eli watched as she transformed into a beautiful woman with flowing red hair. She stepped towards the bushes and out came a small, frightened rabbit. Yumi spoke in a soft, soothing voice, calming the rabbit down.&lt;/p&gt;
&lt;p&gt;Eli was amazed. He had heard stories of kitsunes being able to transform into humans, but seeing it in person was a different experience altogether. He realized that the forest was full of magic and wonder, and he was just beginning to scratch the surface. As they continued their journey, Eli knew that he was in for an adventure of a lifetime.&lt;/p&gt;
&lt;p&gt;As the day wore on, Eli found himself drawn to Yumi. Her strength, her wisdom, and her kindness made him see her in a new light. He admired her courage and her connection with the forest. He found himself wanting to know more about her, to understand her world.&lt;/p&gt;
&lt;p&gt;Yumi, on the other hand, was intrigued by Eli. His bravery, his curiosity, and his respect for the forest made her see him as more than just a human boy. She found herself drawn to his spirit, his zest for life.&lt;/p&gt;
&lt;p&gt;As they journeyed together, their bond deepened. They shared stories, laughed together, and faced challenges together. They found comfort in each other's company, their friendship blossoming into something more. By the time the sun set, painting the sky with hues of pink and orange, they knew that their lives were forever intertwined. They were no longer just a boy and a kitsune, they were partners, ready to face whatever the forest had in store for them.&lt;/p&gt;
&lt;p&gt;Under the starlit sky, Eli took Yumi's hand. His heart pounded in his chest as he looked into her golden eyes. He confessed his feelings for her, his words echoing in the silent forest. Yumi, taken aback, looked at him with a soft smile. She confessed that she too had feelings for him. They shared a tender moment under the Heart Tree, their hearts beating as one. The forest seemed to hold its breath as they leaned in, sharing their first kiss under the twinkling stars. It was a moment of pure magic, a testament to their love.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img alt="Chapter 3" src="/assets/images/articles/ai/fairy_tale_attempt_1/chapter_3.png" /&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Chapter 3: The Whispering Shadows&lt;/p&gt;
&lt;p&gt;After their tender moment under the Heart Tree, Eli and Yumi continued their journey. The forest grew darker, the air colder. They came across an old, abandoned village. The houses were in ruins, the once bustling market now eerily silent.&lt;/p&gt;
&lt;p&gt;Suddenly, they heard a low moan. Turning around, they saw a figure shuffling towards them. Its eyes were vacant, its skin pale. It was a walking dead. Eli felt a chill run down his spine. He had heard stories of the walking dead, but he had never seen one.&lt;/p&gt;
&lt;p&gt;Yumi, sensing his fear, squeezed his hand. She whispered to him, &amp;quot;We must be brave, Eli. The forest needs us.&amp;quot; With a determined look in her eyes, she drew her mystery glowing sword, ready to face the walking dead. Eli, inspired by her courage, lifted a large branch from under his feet. The branch crackled terribly and began to writhe in his hands like a snake, but quickly took on the shape of an elegant blade. Wow! Magic blade from a stick! Eli looked at Yumi, who responded with a wink and a smile. Together, they stood their ground, ready to protect the forest they loved.&lt;/p&gt;
&lt;p&gt;As they stood their ground, the moonlight casting long shadows around them, Eli could feel his heart pounding in his chest. The walking dead moved closer, its movements slow and jerky. Its vacant eyes stared at them, sending a chill down Eli's spine. He tightened his grip on his sword, his knuckles turning white.&lt;/p&gt;
&lt;p&gt;Yumi, on the other hand, stood calm and composed. Her golden eyes glowed in the dark, her red hair flowing in the wind. She looked at the walking dead, not with fear, but with determination. She was ready to protect the forest, to protect Eli.&lt;/p&gt;
&lt;p&gt;The walking dead lunged at them, its arms outstretched. Yumi moved swiftly, her sword slicing through the air. Eli followed her lead, his own sword meeting the walking dead's attack. The fight was intense, the air filled with the sound of clashing swords and the walking dead's eerie moans.&lt;/p&gt;
&lt;p&gt;Despite the fear and the danger, Eli felt a strange sense of exhilaration. He was fighting alongside Yumi, protecting the forest they loved. He realized that this was his destiny, his purpose. He was meant to be here, with Yumi, fighting for the forest.&lt;/p&gt;
&lt;p&gt;As the night wore on, they fought bravely, their swords clashing against the walking dead. Despite the odds, they stood their ground, their determination unwavering. With each passing moment, their bond grew stronger, their love deeper. They fought as one, their movements in perfect sync.&lt;/p&gt;
&lt;p&gt;Finally, as the first rays of dawn pierced the dark sky, they managed to defeat the walking dead. Exhausted but victorious, they stood amidst the ruins of the village, their hearts filled with a sense of accomplishment. They had faced their fears, fought their battles, and protected the forest. Their love story had become a legend, a tale of courage, determination, and love. And as they looked into each other's eyes, they knew that they were ready to face whatever the future had in store for them. Together.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img alt="Epilogue" src="/assets/images/articles/ai/fairy_tale_attempt_1/epilogue.png" /&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Epilogue: The Tragic Separation&lt;/p&gt;
&lt;p&gt;As the victory celebrations faded, the forest spirits gathered around Eli and Yumi. Their faces were somber, their eyes filled with sorrow. They revealed the truth about Yumi - she was a spirit, a ghost of a young girl who had died protecting the forest. Her spirit had taken the form of a kitsune, continuing her duty even in death.&lt;/p&gt;
&lt;p&gt;Eli felt his heart shatter. He had fallen in love with a ghost, a spirit bound to the forest. Their worlds were too different, their existences too incompatible. He held Yumi close, their tears mingling. He whispered a promise to her, a promise to remember her always, to cherish their memories forever.&lt;/p&gt;
&lt;p&gt;Yumi watched Eli leave, her heart aching with a pain she had never known. She had fallen in love with a mortal, a human who lived in a world she could never be a part of. She returned to her duties, her spirit heavy with sorrow. Their love story, though beautiful, was a tale of love and loss, a reminder of the tragic reality of their existence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What do you think? Are you agree that AI can create a dramatic and chilling fable?&lt;/p&gt;
</content><category term="ai"></category><category term="ai"></category><category term="storytelling"></category><category term="openai"></category></entry></feed>